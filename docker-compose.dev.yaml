version: '3.7'
services:
  mongo:
    image: mongo:6.0
    command:
      - bash
      - "-c"
      - |
        echo 'Initializing replica set in the background...'
        (sleep 10; mongosh --eval "try { rs.conf(); } catch (e) { rs.initiate({_id : 'rs0', members: [{ _id: 0, host: 'localhost:27017' }]}); }")&
        echo 'Running mongod in the foreground...'
        exec mongod --replSet rs0 --bind_ip_all
    ports:
      - 27017:27017
    volumes:
      - ./docker-containers/mongo:/data/db
    healthcheck:
      test:
        [
          "CMD",
          "mongosh",
          "--eval",
          "'db.adminCommand(\"ping\")'"
        ]
      interval: 5s
      timeout: 20s
      retries: 10

  redis:
    image: redis:latest
    volumes:
      - ./docker-containers/redis:/data
    ports:
      - 6379:6379
      # - private
    healthcheck:
      test: [ "CMD", "redis-cli", "-h", "redis", "ping" ]
      interval: 5s
      timeout: 20s
      retries: 10

  rabbitmq:
    hostname: rabbitmq
    image: rabbitmq:management
    container_name: rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
    volumes:
      - ./docker-containers/rabbitmq:/var/lib/rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: [ "CMD", "rabbitmqctl", "status" ]
      interval: 5s
      timeout: 15s
      retries: 5

  os01:
    image: opensearchproject/opensearch:2.7.0
    container_name: os01
    environment:
      - cluster.name=os-cluster
      - node.name=os01
      - discovery.seed_hosts=os01,os02
      - cluster.initial_cluster_manager_nodes=os01,os02
      - bootstrap.memory_lock=true
      - "DISABLE_SECURITY_PLUGIN=true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:9200/" ]
      interval: 5s
      timeout: 15s
      retries: 15

    volumes:
      - ./docker-containers/os01:/usr/share/opensearch/data
      # - ./opensearch/opensearch-node.yml:/usr/share/opensearch/config/opensearch.yml
    networks:
      - os-net
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer

  os02:
    image: opensearchproject/opensearch:2.7.0
    container_name: os02
    environment:
      - cluster.name=os-cluster
      - node.name=os02
      - discovery.seed_hosts=os01,os02
      - cluster.initial_cluster_manager_nodes=os01,os02
      - bootstrap.memory_lock=true
      - "DISABLE_SECURITY_PLUGIN=true"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - ./docker-containers/os02:/usr/share/opensearch/data
      # - ./opensearch/opensearch-node.yml:/usr/share/opensearch/config/opensearch.yml
    networks:
      - os-net
    healthcheck:
      test: [ "CMD", "curl", "http://localhost:9200/" ]
      interval: 5s
      timeout: 15s
      retries: 15

  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:2.7.0
    container_name: opensearch-dashboards
    ports:
      - 5601:5601
    expose:
      - "5601"
    environment:
      - 'OPENSEARCH_HOSTS=["http://os01:9200","http://os02:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true" # disables security dashboards plugin in OpenSearch Dashboards
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
    networks:
      - os-net

    depends_on:
      os01:
        condition: service_healthy
      os02:
        condition: service_healthy


  opensearch-dashboards-setup:
    image: opensearchproject/opensearch-dashboards:2.7.0
    restart: "no"
    networks:
      - os-net
    entrypoint:
      - bash
      - "-c"
      - |
        curl --location --request PUT 'http://os01:9200/_cluster/settings' \
          --header 'Content-Type: application/json' \
          --data-raw '{ "transient": { "cluster.routing.allocation.disk.threshold_enabled":false } }' &
        curl --location --request PUT 'http://os02:9200/_cluster/settings' \
          --header 'Content-Type: application/json' \
          --data-raw '{ "transient": { "cluster.routing.allocation.disk.watermark.low": "95%","cluster.routing.allocation.disk.watermark.high": "97%" ,"cluster.routing.allocation.disk.threshold_enabled":false} }' &
        curl --location --request PUT 'http://os01:9200/.kibana_1/_alias/.kibana' &
        curl -X PUT 'http://os01:9200/_cluster/settings' -H 'Content-Type: application/json' -d'
          {
              "persistent" : {
                  "cluster.blocks.create_index" : null
              }
          }'

    depends_on:
      os01:
        condition: service_healthy
      os02:
        condition: service_healthy


networks:
  default:
    driver: bridge
  os-net:
    driver: bridge